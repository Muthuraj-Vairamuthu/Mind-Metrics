{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEW APPROACH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T13:34:45.989490Z",
     "iopub.status.busy": "2025-10-26T13:34:45.989147Z",
     "iopub.status.idle": "2025-10-26T13:35:21.478688Z",
     "shell.execute_reply": "2025-10-26T13:35:21.477679Z",
     "shell.execute_reply.started": "2025-10-26T13:34:45.989466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOAD ===\n",
      "Raw shape: (441456, 22)\n",
      "Raw DIABETE3 (codes) value_counts:\n",
      " DIABETE3\n",
      "1.0     57256\n",
      "2.0      3608\n",
      "3.0    372104\n",
      "4.0      7690\n",
      "7.0       598\n",
      "9.0       193\n",
      "NaN         7\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------------------------\n",
      "=== CLEANING & RECODING ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIABETE3 exclude {7,9}: kept 440665 / dropped 791\n",
      "DIABETE3 (mapped to 0/1/2) value_counts:\n",
      " DIABETE3\n",
      "0.0    375712\n",
      "1.0      7690\n",
      "2.0     57256\n",
      "Name: count, dtype: int64\n",
      "_RFHYPE5 != 9: kept 439407 / dropped 1258\n",
      "TOLDHI2 exclude {7,9}: kept 436136 / dropped 3271\n",
      "_CHOLCHK != 9: kept 421422 / dropped 14714\n",
      "_BMI5 before rounding (describe):\n",
      "count    405058.000000\n",
      "mean       2804.242400\n",
      "std         665.463433\n",
      "min        1202.000000\n",
      "25%        2373.000000\n",
      "50%        2695.000000\n",
      "75%        3090.000000\n",
      "max        9995.000000\n",
      "Name: _BMI5, dtype: float64\n",
      "BMI after rounding to nearest integer (describe):\n",
      "count    387818.000000\n",
      "mean         28.066119\n",
      "std           6.647624\n",
      "min          12.000000\n",
      "25%          24.000000\n",
      "50%          27.000000\n",
      "75%          31.000000\n",
      "max          98.000000\n",
      "Name: _BMI5, dtype: float64\n",
      "SMOKE100 exclude {7,9}: kept 418475 / dropped 2947\n",
      "CVDSTRK3 exclude {7,9}: kept 417464 / dropped 1011\n",
      "_TOTINDA != 9: kept 383139 / dropped 34325\n",
      "_FRTLT1 != 9: kept 372733 / dropped 10406\n",
      "_VEGLT1 != 9: kept 362987 / dropped 9746\n",
      "_RFDRHV5 != 9: kept 357982 / dropped 5005\n",
      "HLTHPLN1 exclude {7,9}: kept 357053 / dropped 929\n",
      "MEDCOST exclude {7,9}: kept 356444 / dropped 609\n",
      "GENHLTH exclude {7,9}: kept 355798 / dropped 646\n",
      "MENTHLTH exclude {77,99}: kept 351830 / dropped 3968\n",
      "PHYSHLTH exclude {77,99}: kept 347345 / dropped 4485\n",
      "DIFFWALK exclude {7,9}: kept 346424 / dropped 921\n",
      "_AGEG5YR != 14: kept 343657 / dropped 2767\n",
      "EDUCA != 9: kept 343136 / dropped 521\n",
      "INCOME2 exclude {77,99}: kept 297445 / dropped 45691\n",
      "dropna(): kept 253680 / dropped 43765\n",
      "------------------------------------------------------------\n",
      "Post-cleaning shape: (253680, 22)\n",
      "Renamed columns. Sample columns:\n",
      " ['GenHlth', 'PhysHlth', 'MentHlth', 'AnyHealthcare', 'NoDocbcCost', 'HighChol', 'Stroke', 'Diabetes_012', 'Sex', 'Education', 'Income', 'DiffWalk', 'Smoker', 'HighBP', 'CholCheck', 'HeartDiseaseorAttack', 'Age', 'BMI', 'HvyAlcoholConsump', 'Fruits', 'Veggies', 'PhysActivity']\n",
      "Saved multiclass cleaned CSV → /kaggle/working/diabetes_012_health_indicators_BRFSS2015.csv\n",
      "Diabetes_012 value_counts:\n",
      " Diabetes_012\n",
      "0.0    213703\n",
      "1.0      4631\n",
      "2.0     35346\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Saved binary cleaned CSV → /kaggle/working/diabetes_binary_health_indicators_BRFSS2015.csv\n",
      "Binary target value_counts (real distribution):\n",
      " Diabetes_binary\n",
      "0.0    213703\n",
      "1.0     39977\n",
      "Name: count, dtype: int64\n",
      "Binary target proportion:\n",
      " Diabetes_binary\n",
      "0.0    0.842412\n",
      "1.0    0.157588\n",
      "Name: proportion, dtype: float64\n",
      "------------------------------------------------------------\n",
      "=== SPLIT ===\n",
      "Train shape: (177576, 21), Test shape: (76104, 21)\n",
      "Train target counts: Counter({0.0: 149592, 1.0: 27984})\n",
      "Test  target counts: Counter({0.0: 64111, 1.0: 11993})\n",
      "Train target ratio: {0.0: 0.8424, 1.0: 0.1576}\n",
      "Test  target ratio: {0.0: 0.8424, 1.0: 0.1576}\n",
      "------------------------------------------------------------\n",
      "=== BALANCING (TRAIN ONLY) ===\n",
      "Original train counts: Counter({0.0: 149592, 1.0: 27984})\n",
      "Over-sampled train counts: Counter({0.0: 149592, 1.0: 149592})\n",
      "Under-sampled train counts: Counter({0.0: 27984, 1.0: 27984})\n",
      "Saved OVER-sampled train → /kaggle/working/X_train_over.csv / /kaggle/working/y_train_over.csv\n",
      "Saved UNDER-sampled train → /kaggle/working/X_train_under.csv / /kaggle/working/y_train_under.csv\n",
      "Saved all files in /kaggle/working/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "CSV_PATH = \"/kaggle/input/behavioral-risk-factor-surveillance-system/2015.csv\"\n",
    "\n",
    "USECOLS = [\n",
    "    'DIABETE3','_RFHYPE5','TOLDHI2','_CHOLCHK','_BMI5','SMOKE100',\n",
    "    'CVDSTRK3','_MICHD','_TOTINDA','_FRTLT1','_VEGLT1','_RFDRHV5',\n",
    "    'HLTHPLN1','MEDCOST','GENHLTH','MENTHLTH','PHYSHLTH','DIFFWALK',\n",
    "    'SEX','_AGEG5YR','EDUCA','INCOME2'\n",
    "]\n",
    "\n",
    "# ---------------------------\n",
    "# 0) Load + baseline metrics\n",
    "# ---------------------------\n",
    "raw = pd.read_csv(CSV_PATH, usecols=USECOLS, low_memory=False)\n",
    "print(\"=== LOAD ===\")\n",
    "print(f\"Raw shape: {raw.shape}\")\n",
    "print(\"Raw DIABETE3 (codes) value_counts:\\n\", raw['DIABETE3'].value_counts(dropna=False).sort_index())\n",
    "print(\"-\" * 60)\n",
    "\n",
    "df = raw.copy()\n",
    "\n",
    "def drop_report(df, mask_keep, desc):\n",
    "    \"\"\"Keep rows where mask_keep is True; report rows dropped.\"\"\"\n",
    "    before = len(df)\n",
    "    df = df[mask_keep].copy()\n",
    "    after = len(df)\n",
    "    print(f\"{desc}: kept {after} / dropped {before - after}\")\n",
    "    return df\n",
    "\n",
    "# Keep a copy of BMI before rounding for comparison\n",
    "_BMI5_before = df['_BMI5'].copy()\n",
    "\n",
    "# ------------------------------------------\n",
    "# 1) BRFSS recodes / drops (with logging)\n",
    "# ------------------------------------------\n",
    "print(\"=== CLEANING & RECODING ===\")\n",
    "\n",
    "df = drop_report(df, ~df['DIABETE3'].isin([7,9]), \"DIABETE3 exclude {7,9}\")\n",
    "df['DIABETE3'] = df['DIABETE3'].replace({2:0, 3:0, 1:2, 4:1})\n",
    "print(\"DIABETE3 (mapped to 0/1/2) value_counts:\\n\", df['DIABETE3'].value_counts().sort_index())\n",
    "\n",
    "df = drop_report(df, df['_RFHYPE5'] != 9, \"_RFHYPE5 != 9\")\n",
    "df['_RFHYPE5'] = df['_RFHYPE5'].replace({1:0, 2:1})\n",
    "\n",
    "df = drop_report(df, ~df['TOLDHI2'].isin([7,9]), \"TOLDHI2 exclude {7,9}\")\n",
    "df['TOLDHI2'] = df['TOLDHI2'].replace({2:0})\n",
    "\n",
    "df = drop_report(df, df['_CHOLCHK'] != 9, \"_CHOLCHK != 9\")\n",
    "df['_CHOLCHK'] = df['_CHOLCHK'].replace({2:0, 3:0})\n",
    "\n",
    "print(f\"_BMI5 before rounding (describe):\\n{_BMI5_before.describe()}\")\n",
    "df['_BMI5'] = (df['_BMI5'] / 100).round(0)\n",
    "print(f\"BMI after rounding to nearest integer (describe):\\n{df['_BMI5'].describe()}\")\n",
    "\n",
    "df = drop_report(df, ~df['SMOKE100'].isin([7,9]), \"SMOKE100 exclude {7,9}\")\n",
    "df['SMOKE100'] = df['SMOKE100'].replace({2:0})\n",
    "\n",
    "df = drop_report(df, ~df['CVDSTRK3'].isin([7,9]), \"CVDSTRK3 exclude {7,9}\")\n",
    "df['CVDSTRK3'] = df['CVDSTRK3'].replace({2:0})\n",
    "\n",
    "df['_MICHD'] = df['_MICHD'].replace({2:0})\n",
    "\n",
    "df = drop_report(df, df['_TOTINDA'] != 9, \"_TOTINDA != 9\")\n",
    "df['_TOTINDA'] = df['_TOTINDA'].replace({2:0})\n",
    "\n",
    "df = drop_report(df, df['_FRTLT1'] != 9, \"_FRTLT1 != 9\")\n",
    "df['_FRTLT1'] = df['_FRTLT1'].replace({2:0})\n",
    "\n",
    "df = drop_report(df, df['_VEGLT1'] != 9, \"_VEGLT1 != 9\")\n",
    "df['_VEGLT1'] = df['_VEGLT1'].replace({2:0})\n",
    "\n",
    "df = drop_report(df, df['_RFDRHV5'] != 9, \"_RFDRHV5 != 9\")\n",
    "df['_RFDRHV5'] = df['_RFDRHV5'].replace({1:0, 2:1})\n",
    "\n",
    "df = drop_report(df, ~df['HLTHPLN1'].isin([7,9]), \"HLTHPLN1 exclude {7,9}\")\n",
    "df['HLTHPLN1'] = df['HLTHPLN1'].replace({2:0})\n",
    "\n",
    "df = drop_report(df, ~df['MEDCOST'].isin([7,9]), \"MEDCOST exclude {7,9}\")\n",
    "df['MEDCOST'] = df['MEDCOST'].replace({2:0})\n",
    "\n",
    "df = drop_report(df, ~df['GENHLTH'].isin([7,9]), \"GENHLTH exclude {7,9}\")\n",
    "\n",
    "df['MENTHLTH'] = df['MENTHLTH'].replace({88:0})\n",
    "df = drop_report(df, ~df['MENTHLTH'].isin([77,99]), \"MENTHLTH exclude {77,99}\")\n",
    "\n",
    "df['PHYSHLTH'] = df['PHYSHLTH'].replace({88:0})\n",
    "df = drop_report(df, ~df['PHYSHLTH'].isin([77,99]), \"PHYSHLTH exclude {77,99}\")\n",
    "\n",
    "df = drop_report(df, ~df['DIFFWALK'].isin([7,9]), \"DIFFWALK exclude {7,9}\")\n",
    "df['DIFFWALK'] = df['DIFFWALK'].replace({2:0})\n",
    "\n",
    "df['SEX'] = df['SEX'].replace({2:0})\n",
    "df = drop_report(df, df['_AGEG5YR'] != 14, \"_AGEG5YR != 14\")\n",
    "df = drop_report(df, df['EDUCA'] != 9, \"EDUCA != 9\")\n",
    "df = drop_report(df, ~df['INCOME2'].isin([77,99]), \"INCOME2 exclude {77,99}\")\n",
    "\n",
    "before_na = len(df)\n",
    "df = df.dropna()\n",
    "print(f\"dropna(): kept {len(df)} / dropped {before_na - len(df)}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"Post-cleaning shape:\", df.shape)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 2) Rename columns \n",
    "# ------------------------------------------\n",
    "df = df.rename(columns={\n",
    "    'DIABETE3':'Diabetes_012','_RFHYPE5':'HighBP','TOLDHI2':'HighChol','_CHOLCHK':'CholCheck',\n",
    "    '_BMI5':'BMI','SMOKE100':'Smoker','CVDSTRK3':'Stroke','_MICHD':'HeartDiseaseorAttack',\n",
    "    '_TOTINDA':'PhysActivity','_FRTLT1':'Fruits','_VEGLT1':'Veggies','_RFDRHV5':'HvyAlcoholConsump',\n",
    "    'HLTHPLN1':'AnyHealthcare','MEDCOST':'NoDocbcCost','GENHLTH':'GenHlth','MENTHLTH':'MentHlth',\n",
    "    'PHYSHLTH':'PhysHlth','DIFFWALK':'DiffWalk','SEX':'Sex','_AGEG5YR':'Age',\n",
    "    'EDUCA':'Education','INCOME2':'Income'\n",
    "})\n",
    "print(\"Renamed columns. Sample columns:\\n\", list(df.columns))\n",
    "\n",
    "# ------------------------------------------\n",
    "# 3) Save cleaned MULTICLASS\n",
    "# ------------------------------------------\n",
    "multi_out = \"/kaggle/working/diabetes_012_health_indicators_BRFSS2015.csv\"\n",
    "df.to_csv(multi_out, index=False)\n",
    "print(f\"Saved multiclass cleaned CSV → {multi_out}\")\n",
    "print(\"Diabetes_012 value_counts:\\n\", df['Diabetes_012'].value_counts().sort_index())\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 4) Make BINARY (1 = prediabetes/diabetes)\n",
    "# ------------------------------------------\n",
    "bin_df = df.copy()\n",
    "bin_df['Diabetes_binary'] = bin_df['Diabetes_012'].replace({0:0, 1:1, 2:1})\n",
    "bin_df = bin_df.drop(columns=['Diabetes_012'])\n",
    "\n",
    "bin_out = \"/kaggle/working/diabetes_binary_health_indicators_BRFSS2015.csv\"\n",
    "bin_df.to_csv(bin_out, index=False)\n",
    "print(f\"Saved binary cleaned CSV → {bin_out}\")\n",
    "print(\"Binary target value_counts (real distribution):\\n\", bin_df['Diabetes_binary'].value_counts())\n",
    "print(\"Binary target proportion:\\n\", (bin_df['Diabetes_binary'].value_counts(normalize=True).sort_index()))\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 5) Stratified split (NO manual 70:30 dataset construction)\n",
    "# ----------------------------------------------------------------\n",
    "X = bin_df.drop(columns=['Diabetes_binary'])\n",
    "y = bin_df['Diabetes_binary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"=== SPLIT ===\")\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "print(\"Train target counts:\", Counter(y_train))\n",
    "print(\"Test  target counts:\", Counter(y_test))\n",
    "print(\"Train target ratio:\", {k: round(v/len(y_train), 4) for k, v in Counter(y_train).items()})\n",
    "print(\"Test  target ratio:\", {k: round(v/len(y_test), 4) for k, v in Counter(y_test).items()})\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 6) Balance ONLY the training set (no external libs)\n",
    "#    A) Random Over-Sampling  (duplicate minority)\n",
    "#    B) Random Under-Sampling (trim majority)\n",
    "# ----------------------------------------------------------------\n",
    "def make_over_sampled_train(X_tr, y_tr):\n",
    "    train = X_tr.copy()\n",
    "    train['Diabetes_binary'] = y_tr.values\n",
    "    counts = train['Diabetes_binary'].value_counts()\n",
    "    maj_class = counts.idxmax()\n",
    "    min_class = counts.idxmin()\n",
    "    n_major = counts.max()\n",
    "    n_minor = counts.min()\n",
    "\n",
    "    # sample minority with replacement to match majority size\n",
    "    minority_df = train[train['Diabetes_binary'] == min_class]\n",
    "    majority_df = train[train['Diabetes_binary'] == maj_class]\n",
    "    needed = n_major - n_minor\n",
    "    boot = minority_df.sample(n=needed, replace=True, random_state=42)\n",
    "    over_df = pd.concat([majority_df, minority_df, boot], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    X_over = over_df.drop(columns=['Diabetes_binary'])\n",
    "    y_over = over_df['Diabetes_binary']\n",
    "    return X_over, y_over\n",
    "\n",
    "def make_under_sampled_train(X_tr, y_tr):\n",
    "    train = X_tr.copy()\n",
    "    train['Diabetes_binary'] = y_tr.values\n",
    "    counts = train['Diabetes_binary'].value_counts()\n",
    "    maj_class = counts.idxmax()\n",
    "    min_class = counts.idxmin()\n",
    "    n_minor = counts.min()\n",
    "\n",
    "    # sample majority without replacement down to minority size\n",
    "    minority_df = train[train['Diabetes_binary'] == min_class]\n",
    "    majority_df = train[train['Diabetes_binary'] == maj_class].sample(n=n_minor, replace=False, random_state=42)\n",
    "    under_df = pd.concat([majority_df, minority_df], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    X_under = under_df.drop(columns=['Diabetes_binary'])\n",
    "    y_under = under_df['Diabetes_binary']\n",
    "    return X_under, y_under\n",
    "\n",
    "X_train_over, y_train_over = make_over_sampled_train(X_train, y_train)\n",
    "X_train_under, y_train_under = make_under_sampled_train(X_train, y_train)\n",
    "\n",
    "print(\"=== BALANCING (TRAIN ONLY) ===\")\n",
    "print(\"Original train counts:\", Counter(y_train))\n",
    "print(\"Over-sampled train counts:\", Counter(y_train_over))\n",
    "print(\"Under-sampled train counts:\", Counter(y_train_under))\n",
    "\n",
    "# Optional: scale after resampling if your models benefit from scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_over_scaled  = scaler.fit_transform(X_train_over)\n",
    "X_train_under_scaled = scaler.fit_transform(X_train_under)\n",
    "X_test_scaled        = scaler.fit_transform(X_test)  # for fairness, fit on train in real pipelines\n",
    "\n",
    "# Save balanced training sets (unscaled) for reproducible experiments\n",
    "over_X_out = \"/kaggle/working/X_train_over.csv\"\n",
    "over_y_out = \"/kaggle/working/y_train_over.csv\"\n",
    "under_X_out = \"/kaggle/working/X_train_under.csv\"\n",
    "under_y_out = \"/kaggle/working/y_train_under.csv\"\n",
    "\n",
    "pd.DataFrame(X_train_over,  columns=X.columns).to_csv(over_X_out, index=False)\n",
    "pd.DataFrame({\"Diabetes_binary\": y_train_over}).to_csv(over_y_out, index=False)\n",
    "\n",
    "pd.DataFrame(X_train_under, columns=X.columns).to_csv(under_X_out, index=False)\n",
    "pd.DataFrame({\"Diabetes_binary\": y_train_under}).to_csv(under_y_out, index=False)\n",
    "\n",
    "print(f\"Saved OVER-sampled train → {over_X_out} / {over_y_out}\")\n",
    "print(f\"Saved UNDER-sampled train → {under_X_out} / {under_y_out}\")\n",
    "print(\"Saved all files in /kaggle/working/\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2192,
     "sourceId": 3692,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8576088,
     "sourceId": 13507427,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
